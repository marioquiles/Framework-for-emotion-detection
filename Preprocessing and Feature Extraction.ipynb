{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, basic EEG signal preprocessing is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files: \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import mne\n",
    "\n",
    "path = \"path of the file to be processed\"\n",
    "\n",
    "raw = pd.read_csv(path) \n",
    "\n",
    "rawMNE = mne.io.RawArray(raw.values, mne.create_info(ch_names=raw.columns, sfreq=256, ch_types=\"eeg\"))\n",
    "\n",
    "# Apply bandpass 4 y 60Hz\n",
    "rawMNE.filter(4, 60, fir_design=\"firwin\")\n",
    "\n",
    "# Apply the notch filter at 50Hz\n",
    "rawMNE.notch_filter(50)\n",
    "\n",
    "# Apply the ICA algorithm\n",
    "ica = mne.preprocessing.ICA(n_components=20)\n",
    "ica.fit(rawMNE)\n",
    "\n",
    "# Obtain the independent components\n",
    "ica_components = ica.get_components()\n",
    "\n",
    "# Apply the independent components to the original signal\n",
    "raw_ica = rawMNE.copy()\n",
    "ica.apply(raw_ica)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, a feature extraction is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain the statistical values of each of the brain rhythms.\n",
    "\n",
    "def get_stadistical_values(channel, data):\n",
    "    # Sampling rate\n",
    "    fs = 256\n",
    "\n",
    "    # Get real amplitudes of FFT (only in postive frequencies)\n",
    "    fft_vals = np.absolute(np.fft.rfft(data[channel]))\n",
    "\n",
    "    # Get frequencies for amplitudes in Hz\n",
    "    fft_freq = np.fft.rfftfreq(len(data[channel]), 1.0/fs)\n",
    "\n",
    "    # Define EEG bands\n",
    "    eeg_bands = {\n",
    "                'Theta': (5, 8),\n",
    "                'Alpha': (8, 12),\n",
    "                'Beta': (12, 30),\n",
    "                'Gamma': (30, 60)}\n",
    "\n",
    "    # Define statistical operations\n",
    "\n",
    "    eeg_band_fft_mean = dict()\n",
    "\n",
    "    eeg_band_fft_variance = dict()\n",
    "\n",
    "    eeg_band_fft_deviation = dict()\n",
    "\n",
    "    eeg_band_fft_max = dict()\n",
    "\n",
    "    eeg_band_fft_sum = dict()\n",
    "\n",
    "    eeg_band_fft_median = dict()\n",
    "\n",
    "\n",
    "    for band in eeg_bands: \n",
    "\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & \n",
    "                        (fft_freq <= eeg_bands[band][1]))[0]\n",
    "        \n",
    "        eeg_band_fft_mean[channel+band+\"_Mean\"] = np.mean(fft_vals[freq_ix])\n",
    "        eeg_band_fft_variance[channel+band+\"_variance\"] = np.var(fft_vals[freq_ix])\n",
    "        eeg_band_fft_deviation[channel+band+\"_deviation\"] = np.std(fft_vals[freq_ix])\n",
    "        eeg_band_fft_max[channel+band+\"_max\"] = np.max(fft_vals[freq_ix])\n",
    "        eeg_band_fft_sum[channel+band+\"_summatory\"] = np.sum(fft_vals[freq_ix])\n",
    "        eeg_band_fft_median[channel+band+\"_median\"] = np.median(fft_vals[freq_ix])\n",
    "    \n",
    "\n",
    "    dfReturned = pd.DataFrame()\n",
    "\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(eeg_band_fft_mean, orient='index'))\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(eeg_band_fft_variance, orient='index'))\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(eeg_band_fft_deviation, orient='index'))\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(eeg_band_fft_max, orient='index'))\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(eeg_band_fft_sum, orient='index'))\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(eeg_band_fft_median, orient='index'))\n",
    "\n",
    "\n",
    "    dfReturned = dfReturned.transpose()\n",
    "\n",
    "    return dfReturned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain the entropy values of the signal\n",
    "\n",
    "import antropy as ant \n",
    "\n",
    "def get_entropy_values(channel, data):\n",
    "    \n",
    "    dictValues = dict()\n",
    "\n",
    "    dictValues[\"Perm_Entropy\"+channel] = ant.perm_entropy(data[channel], normalize=True)\n",
    "    dictValues[\"Spectral_Entropy\"+channel] = ant.spectral_entropy(data[channel], sf=256, method='welch', normalize=True)\n",
    "    dictValues[\"SVD_Entropy\"+channel] = ant.svd_entropy(data[channel], normalize=True)\n",
    "    dictValues[\"APP_Entropy\"+channel] = ant.app_entropy(data[channel])\n",
    "    dictValues[\"Sample_Entropy\"+channel] =  ant.sample_entropy(data[channel])\n",
    "    dictValues[\"Hjorth_Mobility_Entropy\"+channel] =  ant.hjorth_params(data[channel])[0]\n",
    "    dictValues[\"Hjorth_Complexity_Entropy\"+channel] =  ant.hjorth_params(data[channel])[1]\n",
    "    dictValues[\"ZeroCrossings\"+channel] =  ant.num_zerocross(data[channel])\n",
    "\n",
    "    #Fractal dimension\n",
    "\n",
    "    dictValues[\"Petrosian\" + channel] =  ant.petrosian_fd(data[channel])\n",
    "    dictValues[\"Katz\"+channel] =  ant.katz_fd(data[channel])\n",
    "    dictValues[\"Higuchi\"+channel] =  ant.higuchi_fd(data[channel])\n",
    "    dictValues[\"Detrended\"+channel] =  ant.detrended_fluctuation(data[channel])\n",
    "\n",
    "    dfReturned = pd.DataFrame()\n",
    "    dfReturned = dfReturned.append(pd.DataFrame.from_dict(dictValues, orient='index'))\n",
    "\n",
    "    dfReturned = dfReturned.transpose()\n",
    "\n",
    "    return dfReturned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate statistical values with entropy values.\n",
    "\n",
    "def aply_all_channels(workDF):\n",
    "\n",
    "    channels = [\"Fp1\",\"Fp2\",\"F1\",\"F2\",\"F5\",\"F6\",\"O1\",\"O2\"]\n",
    "\n",
    "    allData = pd.DataFrame()\n",
    "\n",
    "    #Bucle para separar en epochs de 4 segundos\n",
    "\n",
    "    for i in range(0, workDF.shape[0]):\n",
    "        \n",
    "        if ((i+1024) > workDF.shape[0]):\n",
    "            break\n",
    "\n",
    "        epoch = workDF.copy().iloc[i:i+1024]\n",
    "        allChanels = pd.DataFrame()\n",
    "\n",
    "        for channel in channels:\n",
    "            aux = get_stadistical_values(channel, epoch)\n",
    "            aux2 = get_entropy_values(channel, epoch)\n",
    "\n",
    "            allChanels = pd.concat([allChanels, aux, aux2], axis=1)\n",
    "\n",
    "        allData = pd.concat([allChanels, allData], axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    return allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to perform this feature extraction from several datasets simultaneously, you can use the following code.\n",
    "\n",
    "%%time \n",
    "from multiprocessing import Pool \n",
    "\n",
    "\n",
    "dataset1,dataset2,dataset3,dataset4 = Pool().map(aply_all_channels, [dataset1.copy(), dataset2.copy(),dataset3.copy(),dataset4.copy() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the datasets to CSV for the following steps\n",
    "\n",
    "dataset1.to_csv(\"dataset1.csv\",index=False)\n",
    "dataset2.to_csv(\"dataset2.csv\",index=False)\n",
    "dataset3.to_csv(\"dataset3.csv\",index=False)\n",
    "dataset4.to_csv(\"dataset4.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "706a7eb66341221f9f9a9abd7958ed5e6a512fe3731f272ffc19509b3625a4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
